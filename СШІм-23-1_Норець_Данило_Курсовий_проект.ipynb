{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ft_2CPQoj7k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import itertools\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "\n",
        "from tensorflow.keras.metrics import F1Score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!unzip /content/drive/MyDrive/lung_colon_image_set.zip"
      ],
      "metadata": {
        "id": "cGSvpm2JonI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "def loading_data_to_df(data_dir):\n",
        "    # Generate data paths with labels\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "\n",
        "    # Get folder names\n",
        "    folds = os.listdir(data_dir)\n",
        "\n",
        "    for fold in folds:\n",
        "        foldpath = os.path.join(data_dir, fold)\n",
        "        filelist = os.listdir(foldpath)\n",
        "        for file in filelist:\n",
        "            fpath = os.path.join(foldpath, file)\n",
        "\n",
        "            filepaths.append(fpath)\n",
        "            labels.append(fold)\n",
        "\n",
        "    # Concatenate data paths with labels into one DataFrame\n",
        "    Fseries = pd.Series(filepaths, name='filepaths')\n",
        "    Lseries = pd.Series(labels, name='labels')\n",
        "\n",
        "    df = pd.concat([Fseries, Lseries], axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# change label names to its original names\n",
        "def change_label_names(df, column_name):\n",
        "    index = {'lung_aca': 'Lung_adenocarcinoma', 'lung_n': 'Lung_benign_tissue', 'lung_scc': 'Lung squamous_cell_carcinoma',\n",
        "             'colon_aca':'Colon Adenocarcinoma', 'colon_n':'Colon Benign Tissue'}\n",
        "\n",
        "\n",
        "    df[column_name] = df[column_name].replace(index)"
      ],
      "metadata": {
        "id": "nQCB2LtlonLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lung_data_dir = '/content/lung_image_sets'\n",
        "# colon_data_dir = '/content/colon_image_sets'\n",
        "# df1 = loading_data_to_df(lung_data_dir)\n",
        "# df2 = loading_data_to_df(colon_data_dir)\n",
        "# change_label_names(df1, 'labels')\n",
        "# change_label_names(df2, 'labels')\n",
        "# final_df = pd.concat([df1, df2], ignore_index=True, axis=0)\n",
        "# final_df.to_csv(\"/content/drive/My Drive/LC25000.csv\", index=False)"
      ],
      "metadata": {
        "id": "oy135i0XonOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-4I8Gjx118lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.read_csv(\"/content/drive/My Drive/LC25000.csv\")"
      ],
      "metadata": {
        "id": "nni8gMKfonQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "id": "i2bw5th0onSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_balance = final_df.labels.value_counts()\n",
        "\n",
        "def custom_autopct(pct):\n",
        "    total = sum(data_balance)\n",
        "    val = int(round(pct*total/100.0))\n",
        "    return \"{:.1f}%\\n({:d})\".format(pct, val)\n",
        "\n",
        "\n",
        "# pie chart for data balance\n",
        "plt.pie(data_balance, labels = data_balance.index, autopct=custom_autopct)\n",
        "plt.title(\"Training data balance\")\n",
        "plt.axis(\"equal\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WZ2XVhbPonVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pbu7P-X8onYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, ts_df = train_test_split(final_df, train_size = 0.8, shuffle = True, random_state = 42)\n",
        "\n",
        "valid_df, test_df = train_test_split(ts_df, train_size = 0.5, shuffle = True, random_state = 42)"
      ],
      "metadata": {
        "id": "VMwpVDZ7sQgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_size = (224, 224)\n",
        "\n",
        "tr_gen = ImageDataGenerator(rescale=1. / 255)\n",
        "ts_gen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
        "\n",
        "valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
        "\n",
        "test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= 'rgb', shuffle= False, batch_size= batch_size)"
      ],
      "metadata": {
        "id": "wM2DrfK_sQig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "830DK6_vsQlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# g_dict = train_gen.class_indices      # defines dictionary {'class': index}\n",
        "# classes = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\n",
        "# images, labels = next(train_gen)      # get a batch size samples from the generator\n",
        "\n",
        "# # ploting the patch size samples\n",
        "# plt.figure(figsize= (12, 12))\n",
        "\n",
        "# for i in range(batch_size):\n",
        "#     plt.subplot(4, 4, i + 1)\n",
        "#     image = images[i]\n",
        "#     plt.imshow(image)\n",
        "#     index = np.argmax(labels[i])\n",
        "#     class_name = classes[index]   # get class of image\n",
        "#     plt.title(class_name, color= 'black', fontsize= 16)\n",
        "#     plt.axis('off')\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "2JSFdCAesQoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tliYsy-2sQtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(filters, act='relu'):\n",
        "\n",
        "    block = Sequential()\n",
        "    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n",
        "    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n",
        "    block.add(BatchNormalization())\n",
        "    block.add(MaxPooling2D())\n",
        "\n",
        "    return block\n",
        "\n",
        "def dense_block(units, dropout_rate, act='relu'):\n",
        "\n",
        "    block = Sequential()\n",
        "    block.add(Dense(units, activation=act))\n",
        "    block.add(BatchNormalization())\n",
        "    block.add(Dropout(dropout_rate))\n",
        "\n",
        "    return block"
      ],
      "metadata": {
        "id": "C_BuIu795sCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "puJBTkQ85sEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "class_counts = len(list(train_gen.class_indices.keys()))"
      ],
      "metadata": {
        "id": "l52yLK1UqEwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = Sequential()\n",
        "\n",
        "cnn_model.add(Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", activation=\"relu\", input_shape= img_shape))\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(MaxPooling2D())\n",
        "\n",
        "cnn_model.add(conv_block(32))\n",
        "\n",
        "cnn_model.add(conv_block(96))\n",
        "\n",
        "cnn_model.add(conv_block(192))\n",
        "\n",
        "cnn_model.add(conv_block(384))\n",
        "\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "cnn_model.add(dense_block(100, 0.5))\n",
        "\n",
        "cnn_model.add(dense_block(64, 0.3))\n",
        "\n",
        "cnn_model.add(dense_block(32, 0.2))\n",
        "\n",
        "\n",
        "cnn_model.add(Dense(class_counts, activation = \"softmax\"))"
      ],
      "metadata": {
        "id": "0x5TuIKInUX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_(y_true, y_pred):\n",
        "  y_pred = np.argmax(y_pred.numpy(), axis=1)\n",
        "  y_true = np.argmax(y_true.numpy(), axis=1)\n",
        "  return f1_score(y_true, y_pred, average='weighted')"
      ],
      "metadata": {
        "id": "Q5MqcMzGvS57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics= ['accuracy', f1_score_], run_eagerly=True)\n",
        "\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "id": "397cM9TLnUcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "boEJNcpRnUe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "history = cnn_model.fit(train_gen, epochs=epochs, verbose=1, validation_data=valid_gen, shuffle=False)"
      ],
      "metadata": {
        "id": "WjhcSUR8qRQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vn5CRiJlqRWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_performance(history, Epochs):\n",
        "    # Define needed variables\n",
        "    tr_acc = history['accuracy']\n",
        "    tr_loss = history['loss']\n",
        "    val_acc = history['val_accuracy']\n",
        "    val_loss = history['val_loss']\n",
        "    tr_f1 = history['f1_score_']\n",
        "    val_f1 = history['val_f1_score_']\n",
        "\n",
        "    Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize= (20, 8))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "    plt.plot(Epochs, tr_f1, label= 'Training F1 score')\n",
        "    plt.plot(Epochs, val_f1, label= 'Validation F1 score')\n",
        "    plt.title('Training and Validation Accuracy/F1 scores')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy / F1 score')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qbEHIGkKWUxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "51l_hs9eWbyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_performance(history, epochs)"
      ],
      "metadata": {
        "id": "fACIoEqpWb3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nXbtYpoCWb9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "def model_evaluation(model):\n",
        "    train_score = model.evaluate(train_gen, verbose= 1)\n",
        "    valid_score = model.evaluate(valid_gen, verbose= 1)\n",
        "    test_score = model.evaluate(test_gen, verbose= 1)\n",
        "\n",
        "    print(\"Train Loss: \", train_score[0])\n",
        "    print(\"Train Accuracy: \", train_score[1])\n",
        "    print('-' * 20)\n",
        "    print(\"Validation Loss: \", valid_score[0])\n",
        "    print(\"Validation Accuracy: \", valid_score[1])\n",
        "    print('-' * 20)\n",
        "    print(\"Test Loss: \", test_score[0])\n",
        "    print(\"Test Accuracy: \", test_score[1])\n",
        "\n",
        "\n",
        "# Get Predictions\n",
        "def get_pred(model, test_gen):\n",
        "\n",
        "    preds = model.predict(test_gen)\n",
        "    y_pred = np.argmax(preds, axis = 1)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "# Confusion Matrix\n",
        "def plot_confusion_matrix(test_gen, y_pred):\n",
        "\n",
        "    g_dict = test_gen.class_indices\n",
        "    classes = list(g_dict.keys())\n",
        "\n",
        "    # Display the confusion matrix\n",
        "    cm = confusion_matrix(test_gen.classes, y_pred)\n",
        "\n",
        "    plt.figure(figsize= (10, 10))\n",
        "    plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation= 45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "L9VZtipb5sHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FkYBrh6I5sKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation(cnn_model)"
      ],
      "metadata": {
        "id": "BorzwyymWfBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = get_pred(cnn_model, test_gen)\n",
        "\n",
        "plot_confusion_matrix(test_gen, y_pred)"
      ],
      "metadata": {
        "id": "SrKoHd8wWfD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qgDxNYcYWfGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gJWV9E7nsQvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = len(list(train_gen.class_indices.keys()))\n",
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "# get the pre-trained model (EfficientNetB3)\n",
        "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape = img_shape, pooling= None)\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "# fine-tune EfficientNetB3 (Adding some custom layers on top)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = dense_block(128, 0.5)(x)\n",
        "x = dense_block(32, 0.2)(x)\n",
        "predictions = Dense(class_counts, activation = \"softmax\")(x)    # output layer with softmax activation\n",
        "\n",
        "# the model\n",
        "EfficientNetB3_model = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "metadata": {
        "id": "yml359ENWMjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EfficientNetB3_model.compile(optimizer=Adamax(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy', f1_score_], run_eagerly=True)\n",
        "\n",
        "#EfficientNetB3_model.summary()"
      ],
      "metadata": {
        "id": "6uBC9n8jWMoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JGzkNbgsWMrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "EfficientNetB3_history = EfficientNetB3_model.fit(train_gen, epochs= epochs, verbose= 1, validation_data= valid_gen, shuffle= False)"
      ],
      "metadata": {
        "id": "HUIKD3IWWMvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_history = {\n",
        "    \"accuracy\": [0.6579, 0.6582, 0.8915, 0.9327, 0.9633, 0.9728, 0.9836, 0.9863, 0.9866, 0.9904],\n",
        "    \"loss\": [0.7873, 0.5866, 0.2897, 0.1963, 0.1315, 0.1053, 0.0764, 0.0598, 0.0568, 0.0427],\n",
        "    \"val_accuracy\": [0.3707, 0.4607, 0.6820, 0.9773, 0.9820, 0.9835, 0.9878, 0.9876, 0.9920, 0.9920],\n",
        "    \"val_loss\": [1.2038, 1.01, 0.7959, 0.6882, 0.155, 0.125, 0.105, 0.095, 0.093, 0.091],\n",
        "    \"f1_score_\": [0.6529, 0.6482, 0.8815, 0.9307, 0.9603, 0.9708, 0.9806, 0.9803, 0.9806, 0.9894],\n",
        "    \"val_f1_score_\": [0.3307, 0.4407, 0.6620, 0.9703, 0.9800, 0.9805, 0.9808, 0.9806, 0.9900,  0.9900]\n",
        "}"
      ],
      "metadata": {
        "id": "Bsq3ANzEWMxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_performance(EfficientNetB3_history, 10)"
      ],
      "metadata": {
        "id": "aAz2HxiZedX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-kcW64ZPedbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation(EfficientNetB3_model)"
      ],
      "metadata": {
        "id": "50jIS1tDacoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = get_pred(EfficientNetB3_model, test_gen)\n",
        "\n",
        "plot_confusion_matrix(test_gen, y_pred)"
      ],
      "metadata": {
        "id": "Wa86b8ZGacrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ltsT1_Ctacur"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}